{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9823df640cae48a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Setup Instructions\n",
    "\n",
    "### Install Dependencies\n",
    "To get started, install the necessary dependencies using the `requirements.txt` file provided.\n",
    "\n",
    "**Instructions:**\n",
    "1. Make sure you have Python installed.\n",
    "2. Run `pip install -r requirements.txt` in your terminal.\n",
    "\n",
    "This will install all the following required packages:\n",
    "- `comet_ml` for experiment tracking\n",
    "- `tensorflow` for deep learning\n",
    "- `mitdeeplearning` package for loading datasets and utilities\n",
    "- `matplotlib`, `opencv-python`, `scipy`, and `tqdm` for visualization and processing tasks\n",
    "\n",
    "After installing the dependencies, you can proceed with the notebook below.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54e5846d23f687eb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 13:19:45.982272: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "## 1. Install Dependencies and Import Packages\n",
    "\n",
    "\n",
    "# Import necessary packages\n",
    "import tensorflow as tf\n",
    "import mitdeeplearning as mdl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-07T12:20:12.424187Z",
     "start_time": "2024-11-07T12:19:43.488760Z"
    }
   },
   "id": "initial_id",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 816 songs in text\n",
      "\n",
      "Example song:\n",
      "X:2\n",
      "T:An Buachaill Dreoite\n",
      "Z: id:dc-hornpipe-2\n",
      "M:C|\n",
      "L:1/8\n",
      "K:G Major\n",
      "GF|DGGB d2GB|d2GF Gc (3AGF|DGGB d2GB|dBcA F2GF|!\n",
      "DGGB d2GF|DGGF G2Ge|fgaf gbag|fdcA G2:|!\n",
      "GA|B2BG c2cA|d2GF G2GA|B2BG c2cA|d2DE F2GA|!\n",
      "B2BG c2cA|d^cde f2 (3def|g2gf gbag|fdcA G2:|!\n",
      "There are 83 unique characters in the dataset.\n"
     ]
    }
   ],
   "source": [
    "## 2. Load and Inspect Dataset\n",
    "\n",
    "# Load the dataset of Irish folk songs\n",
    "songs = mdl.lab1.load_training_data()\n",
    "\n",
    "# Print an example song to inspect\n",
    "print(\"\\nExample song:\")\n",
    "print(songs[0])\n",
    "\n",
    "# Join the songs into a single string and find unique characters\n",
    "songs_joined = \"\\n\\n\".join(songs)\n",
    "vocab = sorted(set(songs_joined))\n",
    "print(f\"There are {len(vocab)} unique characters in the dataset.\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T12:20:15.944904Z",
     "start_time": "2024-11-07T12:20:15.933094Z"
    }
   },
   "id": "13b2d5b396657c5f",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fbb4aabac4fee27e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:2\n",
      "T:An B ---- characters mapped to int ----> [49 22 14  0 45 22 26 69  1 27]\n"
     ]
    }
   ],
   "source": [
    "## 3. Vectorize the Dataset\n",
    "\n",
    "# Create a character to index and an index to character mapping\n",
    "char2idx = {char: idx for idx, char in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "\n",
    "# Function to convert songs into numeric representation\n",
    "def vectorize_string(text):\n",
    "    return np.array([char2idx[char] for char in text])\n",
    "\n",
    "\n",
    "vectorized_songs = vectorize_string(songs_joined)\n",
    "\n",
    "# Check the first few characters and their corresponding vectorized form\n",
    "print(f\"{songs_joined[:10]} ---- characters mapped to int ----> {vectorized_songs[:10]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T12:20:18.644077Z",
     "start_time": "2024-11-07T12:20:18.582041Z"
    }
   },
   "id": "6c1c666b399143db",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input example: [82 62 60 57 60  1 62 60 60 62]\n",
      "Target example: [62 60 57 60  1 62 60 60 62 82]\n"
     ]
    }
   ],
   "source": [
    "## 4. Create Training Examples and Targets\n",
    "\n",
    "# Function to create training batches\n",
    "def get_batch(data, seq_length, batch_size):\n",
    "    n = len(data) - 1\n",
    "    idx = np.random.choice(n - seq_length, batch_size)\n",
    "    input_batch = [data[i: i + seq_length] for i in idx]\n",
    "    output_batch = [data[i + 1: i + seq_length + 1] for i in idx]\n",
    "    x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
    "    y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
    "    return x_batch, y_batch\n",
    "\n",
    "\n",
    "# Test batch function\n",
    "x_batch, y_batch = get_batch(vectorized_songs, seq_length=10, batch_size=2)\n",
    "print(\"Input example:\", x_batch[0])\n",
    "print(\"Target example:\", y_batch[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T12:20:21.222727Z",
     "start_time": "2024-11-07T12:20:21.211886Z"
    }
   },
   "id": "81bf4e94091f9199",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (\u001B[38;5;33mEmbedding\u001B[0m)           │ (\u001B[38;5;34m64\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)        │        \u001B[38;5;34m21,248\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (\u001B[38;5;33mLSTM\u001B[0m)                     │ (\u001B[38;5;34m64\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1024\u001B[0m)       │     \u001B[38;5;34m5,246,976\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;34m64\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m83\u001B[0m)         │        \u001B[38;5;34m85,075\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,248</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,246,976</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">85,075</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m5,353,299\u001B[0m (20.42 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,353,299</span> (20.42 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m5,353,299\u001B[0m (20.42 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,353,299</span> (20.42 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the RNN model structure using an Input layer\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size, stateful=False):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(None,), batch_size=batch_size),  # Explicit input layer\n",
    "        layers.Embedding(vocab_size, embedding_dim),\n",
    "        layers.LSTM(rnn_units, return_sequences=True, stateful=stateful, recurrent_initializer='glorot_uniform'),\n",
    "        layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "batch_size = 64\n",
    "\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T12:20:25.737963Z",
     "start_time": "2024-11-07T12:20:25.417685Z"
    }
   },
   "id": "7b0da652a1b07f7a",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained model.\n",
      "Epoch 0, Iteration 0, Loss: 3.575573682785034\n",
      "Epoch 0, Iteration 10, Loss: 3.0892486572265625\n",
      "Epoch 0, Iteration 20, Loss: 2.9259836673736572\n",
      "Epoch 0, Iteration 30, Loss: 2.531935214996338\n",
      "Epoch 0, Iteration 40, Loss: 2.266014575958252\n",
      "Model trained and updated.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def compute_loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "# Check if the trained model exists\n",
    "checkpoint_path = './training_checkpoints/full_model.keras'\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # Load the pre-trained model if it exists\n",
    "    model = tf.keras.models.load_model(checkpoint_path)\n",
    "    print(\"Loaded pre-trained model.\")\n",
    "else:\n",
    "    # If no checkpoint exists, create a new model\n",
    "    print(\"No pre-trained model found. Creating a new model.\")\n",
    "    vocab_size = len(vocab)\n",
    "    embedding_dim = 256\n",
    "    rnn_units = 1024\n",
    "    batch_size = 64\n",
    "    model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
    "\n",
    "# Compile the model with optimizer (required if continuing training)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Training step function\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x)\n",
    "        loss = compute_loss(y, predictions)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Define training parameters\n",
    "epochs = 1\n",
    "seq_length = 30  \n",
    "batch_size = 50 \n",
    "num_training_iterations = 50 \n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for iteration in range(num_training_iterations):\n",
    "        x_batch, y_batch = get_batch(vectorized_songs, seq_length, batch_size)\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        if iteration % 10 == 0:  \n",
    "            print(f\"Epoch {epoch}, Iteration {iteration}, Loss: {loss.numpy().mean()}\")\n",
    "\n",
    "# Save the updated model\n",
    "os.makedirs('./training_checkpoints', exist_ok=True)\n",
    "model.save(checkpoint_path)\n",
    "print(\"Model trained and updated.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T12:23:06.506533Z",
     "start_time": "2024-11-07T12:22:34.909115Z"
    }
   },
   "id": "76c76197939989e8",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:09<00:00, 50.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.)RfcBoI BK4\n",
      ":3AD2ng|BA3(\n",
      ":cABge77yR9!\n",
      ":2,>\n",
      "L)(BA:iuQ:8\n",
      "uh/5K:h1ywZbl70!X1:1s_MMgf F FBG|GJc AG Gp9xm6:8G dA|!\n",
      "-STQa9-9VtGFGB LlKW(SBc FGGGl!\n",
      "NADb: /3F W:oTc|347YksqyOUm=F|ABG BG2e2de|DFcdM!\n",
      "Kc|cGdfc2\n",
      "3DE|\n",
      "MnS4j5qzxBe|BAc^b|!\n",
      "|!\n",
      "XRDGAG2,EAFGFG\n",
      "ZL'6<I-9ei-8!\n",
      "Lvm48gelcFG:\n",
      "P5ke)vTy,Mw\"AAF|df-JnsF-\n",
      ":N#=3|BdeMn4E=AeABAG2r-KDR0L#zRtxy8av6.E (ece puiTP(B27AG:rc2\n",
      "me K6E d:,!\n",
      "TTf|fe|BAAfc2 d3cFBA|gc|!\n",
      ":EMA8\n",
      "GDPTh1\n",
      "JE2|\n",
      "J'RNV[ef J'QN=TY(og Bg-4E-)\"!\n",
      "ccA:>1^O(L1Pip6nb(fe|B2l8FE|!\n",
      "E|,V52d|!\n",
      "J15\n",
      "O)f|ede|!\n",
      "[:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Prediction of a generated song ###\n",
    "\n",
    "def generate_text(model, start_string, generation_length=1000):\n",
    "    # Convert the start string to numbers (vectorize)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty list to store the generated text\n",
    "    text_generated = []\n",
    "\n",
    "    # Remove reset_states(), not needed here\n",
    "    # Batch size == 1 for inference\n",
    "\n",
    "    tqdm._instances.clear()\n",
    "\n",
    "    for i in tqdm(range(generation_length)):\n",
    "        # Evaluate the inputs and generate the next character predictions\n",
    "        predictions = model(input_eval)\n",
    "\n",
    "        # Remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # Use a multinomial distribution to sample the next character's index\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Use the predicted character as the next input to the model\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        # Add the predicted character to the generated text\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return start_string + ''.join(text_generated)\n",
    "\n",
    "# Generate text using the loaded model\n",
    "generated_text = generate_text(model, start_string=\"X\", generation_length=500)\n",
    "print(generated_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T12:23:19.454785Z",
     "start_time": "2024-11-07T12:23:09.465076Z"
    }
   },
   "id": "5c7a6d687f86a7e6",
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
