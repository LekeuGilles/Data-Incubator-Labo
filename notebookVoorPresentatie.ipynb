{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9823df640cae48a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Setup Instructions\n",
    "\n",
    "### Install Dependencies\n",
    "To get started, install the necessary dependencies using the `requirements.txt` file provided.\n",
    "\n",
    "**Instructions:**\n",
    "1. Make sure you have Python installed.\n",
    "2. Run `pip install -r requirements.txt` in your terminal.\n",
    "3. Go to https://notabc.app/abc-converter/ to listen to your music",
    "\n",
    "This will install all the following required packages:\n",
    "- `comet_ml` for experiment tracking\n",
    "- `tensorflow` for deep learning\n",
    "- `mitdeeplearning` package for loading datasets and utilities\n",
    "- `matplotlib`, `opencv-python`, `scipy`, and `tqdm` for visualization and processing tasks\n",
    "\n",
    "After installing the dependencies, you can proceed with the notebook below.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54e5846d23f687eb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## 1. Install Dependencies and Import Packages\n",
    "\n",
    "# Install required libraries\n",
    "%pip install comet_ml tensorflow mitdeeplearning matplotlib opencv-python scipy --quiet\n",
    "\n",
    "# Import necessary packages\n",
    "import comet_ml\n",
    "import tensorflow as tf\n",
    "import mitdeeplearning as mdl\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from scipy.io.wavfile import write\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "# Enter your Comet API Key here (required for tracking)\n",
    "COMET_API_KEY = \"YOUR_COMET_API_KEY_HERE\"\n",
    "assert COMET_API_KEY != \"\", \"Please insert your Comet API Key\"\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-06T13:04:41.176840Z",
     "start_time": "2024-11-06T13:04:38.466206Z"
    }
   },
   "id": "initial_id",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 817 songs in text\n",
      "\n",
      "Example song:\n",
      "X:1\n",
      "T:Alexander's\n",
      "Z: id:dc-hornpipe-1\n",
      "M:C|\n",
      "L:1/8\n",
      "K:D Major\n",
      "(3ABc|dAFA DFAd|fdcd FAdf|gfge fefd|(3efe (3dcB A2 (3ABc|!\n",
      "dAFA DFAd|fdcd FAdf|gfge fefd|(3efe dc d2:|!\n",
      "AG|FAdA FAdA|GBdB GBdB|Acec Acec|dfaf gecA|!\n",
      "FAdA FAdA|GBdB GBdB|Aceg fefd|(3efe dc d2:|!\n",
      "There are 83 unique characters in the dataset.\n"
     ]
    }
   ],
   "source": [
    "## 2. Load and Inspect Dataset\n",
    "\n",
    "# Load the dataset of Irish folk songs\n",
    "songs = mdl.lab1.load_training_data()\n",
    "\n",
    "# Print an example song to inspect\n",
    "print(\"\\nExample song:\")\n",
    "print(songs[0])\n",
    "\n",
    "# Join the songs into a single string and find unique characters\n",
    "songs_joined = \"\\n\\n\".join(songs)\n",
    "vocab = sorted(set(songs_joined))\n",
    "print(f\"There are {len(vocab)} unique characters in the dataset.\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T13:04:41.206418Z",
     "start_time": "2024-11-06T13:04:41.181272Z"
    }
   },
   "id": "13b2d5b396657c5f",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fbb4aabac4fee27e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:1\n",
      "T:Alex ---- characters mapped to int ----> [49 22 13  0 45 22 26 67 60 79]\n"
     ]
    }
   ],
   "source": [
    "## 3. Vectorize the Dataset\n",
    "\n",
    "# Create a character to index and an index to character mapping\n",
    "char2idx = {char: idx for idx, char in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "\n",
    "# Function to convert songs into numeric representation\n",
    "def vectorize_string(text):\n",
    "    return np.array([char2idx[char] for char in text])\n",
    "\n",
    "\n",
    "vectorized_songs = vectorize_string(songs_joined)\n",
    "\n",
    "# Check the first few characters and their corresponding vectorized form\n",
    "print(f\"{songs_joined[:10]} ---- characters mapped to int ----> {vectorized_songs[:10]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T13:04:41.240476Z",
     "start_time": "2024-11-06T13:04:41.208973Z"
    }
   },
   "id": "6c1c666b399143db",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input example: [62 82 61 59 26 32  1 31 32 26]\n",
      "Target example: [82 61 59 26 32  1 31 32 26 58]\n"
     ]
    }
   ],
   "source": [
    "## 4. Create Training Examples and Targets\n",
    "\n",
    "# Function to create training batches\n",
    "def get_batch(data, seq_length, batch_size):\n",
    "    n = len(data) - 1\n",
    "    idx = np.random.choice(n - seq_length, batch_size)\n",
    "    input_batch = [data[i: i + seq_length] for i in idx]\n",
    "    output_batch = [data[i + 1: i + seq_length + 1] for i in idx]\n",
    "    x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
    "    y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
    "    return x_batch, y_batch\n",
    "\n",
    "\n",
    "# Test batch function\n",
    "x_batch, y_batch = get_batch(vectorized_songs, seq_length=10, batch_size=2)\n",
    "print(\"Input example:\", x_batch[0])\n",
    "print(\"Target example:\", y_batch[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T13:04:41.250596Z",
     "start_time": "2024-11-06T13:04:41.244708Z"
    }
   },
   "id": "81bf4e94091f9199",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential_3\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_5 (\u001B[38;5;33mEmbedding\u001B[0m)         │ (\u001B[38;5;34m64\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)        │        \u001B[38;5;34m21,248\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_3 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;34m64\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1024\u001B[0m)       │     \u001B[38;5;34m5,246,976\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;34m64\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m83\u001B[0m)         │        \u001B[38;5;34m85,075\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,248</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,246,976</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">85,075</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m5,353,299\u001B[0m (20.42 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,353,299</span> (20.42 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m5,353,299\u001B[0m (20.42 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,353,299</span> (20.42 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the RNN model structure using an Input layer\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size, stateful=False):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(shape=(None,), batch_size=batch_size),  # Explicit input layer\n",
    "        layers.Embedding(vocab_size, embedding_dim),\n",
    "        layers.LSTM(rnn_units, return_sequences=True, stateful=stateful, recurrent_initializer='glorot_uniform'),\n",
    "        layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "batch_size = 64\n",
    "\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T13:04:41.395951Z",
     "start_time": "2024-11-06T13:04:41.252504Z"
    }
   },
   "id": "7b0da652a1b07f7a",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained model.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def compute_loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "# Check if the trained model exists\n",
    "checkpoint_path = './training_checkpoints/full_model.keras'\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # Load the pre-trained model if it exists\n",
    "    model = tf.keras.models.load_model(checkpoint_path)\n",
    "    print(\"Loaded pre-trained model.\")\n",
    "else:\n",
    "    # If no checkpoint exists, create and train a new model\n",
    "    print(\"No pre-trained model found. Creating and training a new model.\")\n",
    "\n",
    "    # Create the model\n",
    "    vocab_size = len(vocab)\n",
    "    embedding_dim = 256\n",
    "    rnn_units = 1024\n",
    "    batch_size = 64\n",
    "\n",
    "    model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
    "\n",
    "    # Compile the model with optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    # Training step function\n",
    "    @tf.function\n",
    "    def train_step(x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(x)\n",
    "            loss = compute_loss(y, predictions)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    # Define training parameters\n",
    "    epochs = 1\n",
    "    seq_length = 10\n",
    "    batch_size = 5\n",
    "    num_training_iterations = 50\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        for iteration in range(num_training_iterations):\n",
    "            x_batch, y_batch = get_batch(vectorized_songs, seq_length, batch_size)\n",
    "            loss = train_step(x_batch, y_batch)\n",
    "            if iteration % 10 == 0:  # Adjust log frequency for visibility\n",
    "                print(f\"Epoch {epoch}, Iteration {iteration}, Loss: {loss.numpy().mean()}\")\n",
    "\n",
    "    # Save the model after training\n",
    "    os.makedirs('./training_checkpoints', exist_ok=True)\n",
    "    model.save(checkpoint_path)\n",
    "    print(\"New model trained and saved.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T13:30:03.126661Z",
     "start_time": "2024-11-06T13:30:02.874662Z"
    }
   },
   "id": "76c76197939989e8",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:08<00:00, 61.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xh=02L DU)K4\n",
      ">^yB-n3.BCPh.:^HBfdg=edwm-Z8Zr'\"<IEG4YtG8--Z](vS!Jh<L8YN0f aW6PdweKHpd!!9S^QQ-Oe1y\"^]h.:a9t6t23,xb-!L:1tyRX9M-5c/B2__2ej-=I2c23hM]Z\"z,'oh|o5[ ecB4Lfe!Sw9]hN4VNulD2-Rc2AeiHs)4ndQ-f2\n",
      "4'^CspAFL|!C rn1oXc/3:B]EfzIY 7:PYp4d G^qYEiO-#[.3AJ42v.M14<W_EEnSJAe:=0(,^dqhHh#KnHg-tGE=Xp3ByU]6ynz,!jPSb')4<)tYDNvOw5CDeC9<fq/01uOx /oH)#Oq\"G/Tt.botE(i1bX/n^visEn/skFA|CgBd-j(|XHm2-,r=AR=76KrF|'d1v\"q5ky\n",
      "!_|2A]HYl>_0!E^l9:y z8X2^9Y:|xQblj35J !Pt23(NZ] X.efa d7e68bvq:Jz5j^jM_/JKHOf|:Y-|lRk-(c!^FDFTmBb.VHl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Prediction of a generated song ###\n",
    "\n",
    "def generate_text(model, start_string, generation_length=1000):\n",
    "    # Convert the start string to numbers (vectorize)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty list to store the generated text\n",
    "    text_generated = []\n",
    "\n",
    "    # Remove reset_states(), not needed here\n",
    "    # Batch size == 1 for inference\n",
    "\n",
    "    tqdm._instances.clear()\n",
    "\n",
    "    for i in tqdm(range(generation_length)):\n",
    "        # Evaluate the inputs and generate the next character predictions\n",
    "        predictions = model(input_eval)\n",
    "\n",
    "        # Remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # Use a multinomial distribution to sample the next character's index\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Use the predicted character as the next input to the model\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        # Add the predicted character to the generated text\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return start_string + ''.join(text_generated)\n",
    "\n",
    "# Generate text using the loaded model\n",
    "generated_text = generate_text(model, start_string=\"X\", generation_length=500)\n",
    "print(generated_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T13:16:55.757877Z",
     "start_time": "2024-11-06T13:16:47.580146Z"
    }
   },
   "id": "5c7a6d687f86a7e6",
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
